{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# MovieLens names are wrong, but use it to initialize\n",
    "id2name = {}\n",
    "for line in open('movies.dat'): \n",
    "    id, name, type = line.strip().split('::')\n",
    "    id = int(id)\n",
    "    assert(name[-1] == ')' and name[-6] == '(')\n",
    "    id2name[id] = name[:-6].strip()\n",
    "\n",
    "# Update new name from Hao's metadata, some ids are missing\n",
    "for item in pd.read_csv('ML1M_Meta_3670.csv').values.tolist():\n",
    "    id2name[item[0]] = item[3]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "oldid2newid = {} # trim empty ids\n",
    "for new_id, old_id in enumerate(sorted(id2name.keys())): oldid2newid[old_id] = new_id\n",
    "id2name = [id2name[id] for id in sorted(id2name.keys())]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "user2ids = {}\n",
    "for line in open('ratings.dat'):\n",
    "    user, id, rating, time = line.strip().split('::')\n",
    "    user, id, rating, time = int(user), oldid2newid[int(id)], int(rating), int(time)\n",
    "    if user not in user2ids: user2ids[user] = []\n",
    "    user2ids[user].append((id, time))\n",
    "for user in user2ids:\n",
    "    user2ids[user] = sorted(user2ids[user], key=lambda x: x[1])\n",
    "    user2ids[user], _ = zip(*user2ids[user])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print('# user:', len(user2ids), ',', '# movie:', len(id2name), ',', '# interaction:', sum([len(user2ids[user]) for user in user2ids]))\n",
    "print('History:', stats.describe([len(user2ids[user]) for user in user2ids]))\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "print('# words in movie name:', stats.describe([len(name.split()) for name in id2name]))\n",
    "print('# tokens in movie name:', stats.describe([len(tokenizer(name, add_special_tokens=False)['input_ids']) for name in id2name]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# user: 6040 , # movie: 3883 , # interaction: 1000209\n",
      "History: DescribeResult(nobs=6040, minmax=(20, 2314), mean=165.5975165562914, variance=37151.41721522576, skewness=2.743966112411747, kurtosis=11.1920071429534)\n",
      "# words in movie name: DescribeResult(nobs=3883, minmax=(1, 15), mean=2.8532062838011845, variance=2.672933431676114, skewness=1.5587508576280893, kurtosis=4.413184077254987)\n",
      "# tokens in movie name: DescribeResult(nobs=3883, minmax=(1, 25), mean=4.110739119237703, variance=5.747651256756257, skewness=2.024892296904092, kurtosis=7.619923800325971)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def save_jsonl(data, filename):\n",
    "    with open(filename, 'w') as fout:\n",
    "        for item in data:\n",
    "            fout.write(json.dumps(item) + '\\n')\n",
    "\n",
    "data = [{'user': user, 'ids': user2ids[user]} for user in user2ids]\n",
    "save_jsonl(data, 'data.jsonl')\n",
    "json.dump(id2name, open('id2name.json', 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "user = 1\n",
    "print(data[user - 1]['ids'], len(data[user - 1]['ids']))\n",
    "print(user2ids[user], len(user2ids[user]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3117, 1250, 1672, 1009, 2271, 1768, 3339, 2735, 1189, 1176, 711, 257, 907, 604, 2623, 1892, 1959, 3036, 926, 1022, 1893, 1949, 148, 1015, 1081, 902, 1267, 2728, 2693, 1226, 655, 2849, 527, 3045, 2722, 2252, 1016, 1179, 590, 2329, 1506, 523, 591, 2618, 735, 584, 0, 2286, 2225, 773, 1526, 1838, 47) 53\n",
      "(3117, 1250, 1672, 1009, 2271, 1768, 3339, 2735, 1189, 1176, 711, 257, 907, 604, 2623, 1892, 1959, 3036, 926, 1022, 1893, 1949, 148, 1015, 1081, 902, 1267, 2728, 2693, 1226, 655, 2849, 527, 3045, 2722, 2252, 1016, 1179, 590, 2329, 1506, 523, 591, 2618, 735, 584, 0, 2286, 2225, 773, 1526, 1838, 47) 53\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zero-shot PET"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def convert(ids, n_pad=10):\n",
    "    s = 'A user watched '\n",
    "    for id in ids:\n",
    "        s += id2name[id] + ', '\n",
    "    s = s.strip()[:-1] + '. '\n",
    "    s += 'Now the user may want to watch '\n",
    "    s += tokenizer.mask_token * n_pad\n",
    "    s += '.'\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = [json.loads(line) for line in open('data.jsonl')]\n",
    "id2name = json.load(open('id2name.json'))\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model = model.eval()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "model(**tokenizer(['hello world'], return_tensors='pt')).logits[0].softmax(-1).log().exp().sum(-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "tokenizer(convert(data[0]['ids'], n_pad=5))['input_ids'][-12:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5310, 2089, 2215, 2000, 3422, 103, 103, 103, 103, 103, 1012, 102]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "id2tokens = []\n",
    "for name in id2name:\n",
    "    id2tokens.append(tokenizer(name, add_special_tokens=False)['input_ids'][:10])\n",
    "print(max([len(tokens) for tokens in id2tokens]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def score(ids):\n",
    "    input = tokenizer([convert(ids)], max_length=500, return_tensors='pt')\n",
    "    # input = {key: input[key].cuda() for key in input}\n",
    "    output = model(**input)\n",
    "    logits = output.logits[0].softmax(-1).log().detach().cpu().numpy()\n",
    "    id2score = []\n",
    "    for tokens in id2tokens:\n",
    "        id2score.append([])\n",
    "        for i, tok_id in enumerate(tokens):\n",
    "            id2score[-1].append(logits[-12 + i, tok_id].item())\n",
    "        # id2score[id] = np.mean(id2score[id])\n",
    "    return id2score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def evaluate(data):\n",
    "    scores = [score(item['ids'][:5]) for item in tqdm(data)]\n",
    "    return scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "scores = evaluate(data[:50])"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def compute_metrics(data, scores):\n",
    "    assert(len(data) == len(scores))\n",
    "    r_20 = []\n",
    "    for item, id2score in tqdm(zip(data, scores)):\n",
    "        id2score = {id: np.max(id2score[id]) for id in id2score}\n",
    "        top_ids = sorted(id2score.items(), key=lambda x:x[1], reverse=True)\n",
    "        top_ids, _ = zip(*top_ids)\n",
    "        r_20.append(item['val_id'] in top_ids[:20])\n",
    "    print(np.mean(r_20))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "compute_metrics(data, scores)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127350/2367012091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "id2name.index('Contempt')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1532"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "idx += 1\n",
    "ids, label = data[idx]['ids'][:7][:-2], data[idx]['ids'][:7][-2]\n",
    "id2score = score(ids)\n",
    "id2score = {i: np.mean(score) for i, score in enumerate(id2score)} # TODO: np.mean\n",
    "top_ids = sorted(id2score.items(), key=lambda x:x[1], reverse=True)\n",
    "top_ids, _ = zip(*top_ids)\n",
    "\n",
    "print(convert(ids))\n",
    "print()\n",
    "print('\\n'.join([str((id2name[id], id2score[id])) for id in top_ids[:5]]))\n",
    "print()\n",
    "print('\\n'.join([str((id2name[id], id2score[id])) for id in top_ids[-5:]]))\n",
    "print()\n",
    "print(id2name[label], top_ids.index(label))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A user watched Raiders of the Lost Ark, Ghost, The Perfect Storm, The Shawshank Redemption, The Silence of the Lambs. Now the user may want to watch [MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK].\n",
      "\n",
      "('If....', -3.693471097946167)\n",
      "('The Show', -4.037599563598633)\n",
      "('Them!', -4.9892332553863525)\n",
      "('The Program', -5.034773111343384)\n",
      "('The Fly', -5.152930498123169)\n",
      "\n",
      "('Duets', -17.51946258544922)\n",
      "('Persuasion', -17.645301818847656)\n",
      "('Sprung', -18.321044921875)\n",
      "('Nowhere', -18.484943389892578)\n",
      "('Trois', -19.61321449279785)\n",
      "\n",
      "The Usual Suspects 1500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simpler Case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def convert(ids, n_pad=10):\n",
    "    s = 'A user has bought '\n",
    "    for id in ids:\n",
    "        s += id2name[id] + '; '\n",
    "    s = s.strip()[:-1] + '. '\n",
    "    s += 'Now the user wants to buy'\n",
    "    s += '[MASK]' * n_pad\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = AutoModelForMaskedLM.from_pretrained('bert-base-cased').cuda()\n",
    "model = model.eval()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "id2name = {1: 'apple', 2: 'banana', 3: 'mango', 4: 'MP3', 5: 'computer', 6: 'laptop', 7: 'mobile phone', 8: 'pen'}\n",
    "id2tokens = {}\n",
    "for id in id2name:\n",
    "    id2tokens[id] = tokenizer(id2name[id], add_special_tokens=False)['input_ids'][:10]\n",
    "print(id2tokens)\n",
    "print(max([len(id2tokens[id]) for id in id2tokens]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1: [12075], 2: [21806], 3: [1299, 2758], 4: [5478, 1495], 5: [2775], 6: [12574], 7: [5093, 2179], 8: [8228]}\n",
      "2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "ids = [1,2]\n",
    "id2score = score(ids)\n",
    "print(convert(ids))\n",
    "id2score = {id: np.mean(id2score[id]) for id in id2score}\n",
    "top_ids = sorted(id2score.items(), key=lambda x:x[1], reverse=True)\n",
    "print(top_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A user has bought apple; banana. Now the user wants to buy[MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK][MASK]\n",
      "[(2, 9.848603248596191), (1, 9.236679077148438), (5, 1.58921480178833), (3, 0.9985607117414474), (6, 0.48988187313079834), (8, 0.07451194524765015), (7, -0.29580698907375336), (4, -0.3808416575193405)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "source": [
    "input = tokenizer('hello world', max_length=500, return_tensors='pt')\n",
    "input = {key: input[key].cuda() for key in input}\n",
    "output = model(**input)\n",
    "logits = output.logits[0].detach().cpu().numpy()\n",
    "print(logits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ -7.5906496  -7.4921894  -7.673322  ...  -6.4238377  -6.172981\n",
      "   -6.539128 ]\n",
      " [ -7.8396683  -8.055583   -7.957813  ...  -6.5347376  -6.4125085\n",
      "   -6.7794714]\n",
      " [ -9.92513    -9.655717   -9.891573  ...  -5.8455057  -6.6210732\n",
      "   -7.4404745]\n",
      " [-13.494137  -13.658618  -13.19817   ... -10.935408  -10.908022\n",
      "  -11.860087 ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "idx = torch.tensor([[0,1], [1,2], [2,3]])\n",
    "# expected output:\n",
    "# tensor([[[ 0,  1,  2,  3,  4],\n",
    "#          [ 5,  6,  7,  8,  9]],\n",
    "\n",
    "#         [[25, 26, 27, 28, 29],\n",
    "#          [30, 31, 32, 33, 34]],\n",
    "\n",
    "#         [[50, 51, 52, 53, 54],\n",
    "#          [55, 56, 57, 58, 59]]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "a[torch.arange(3).unsqueeze(-1), idx]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "        [[25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34]],\n",
       "\n",
       "        [[50, 51, 52, 53, 54],\n",
       "         [55, 56, 57, 58, 59]]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "b = torch.arange(60).reshape(4,3,5)\n",
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14]],\n",
       "\n",
       "        [[15, 16, 17, 18, 19],\n",
       "         [20, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 29]],\n",
       "\n",
       "        [[30, 31, 32, 33, 34],\n",
       "         [35, 36, 37, 38, 39],\n",
       "         [40, 41, 42, 43, 44]],\n",
       "\n",
       "        [[45, 46, 47, 48, 49],\n",
       "         [50, 51, 52, 53, 54],\n",
       "         [55, 56, 57, 58, 59]]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "b[:, [[0,1,2]], [[1,2,3], [2,3,4], [0,1,2]]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1,  7, 13],\n",
       "         [ 2,  8, 14],\n",
       "         [ 0,  6, 12]],\n",
       "\n",
       "        [[16, 22, 28],\n",
       "         [17, 23, 29],\n",
       "         [15, 21, 27]],\n",
       "\n",
       "        [[31, 37, 43],\n",
       "         [32, 38, 44],\n",
       "         [30, 36, 42]],\n",
       "\n",
       "        [[46, 52, 58],\n",
       "         [47, 53, 59],\n",
       "         [45, 51, 57]]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer('hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello ', add_special_tokens=False, padding='max_length', max_length=10, truncation=True)['input_ids']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[19082, 19082, 19082, 19082, 19082, 19082, 19082, 19082, 19082, 19082]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "np.array([1,3,2]).argsort().reshape(-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import torch.nn as nn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "softmax = nn.Softmax()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "a = torch.arange(15).reshape(3,5)\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "a[[0,1,2],[0,2,1]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0,  7, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "e329eaacdde1c3f16b1d348b966d5b9ad2a51ea4006f452504e74c885ba70bb5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}